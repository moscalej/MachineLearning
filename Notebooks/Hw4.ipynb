{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Question 1\n",
    "$$f(x,y) = 80x^4 + 0.01y^2$$\n",
    "we can see that $f(x,y)$ is convex and is the sum of two parabolas there for the miniminun of the function is the minimun of the sum $min_{x,y} f(x,y) = min_x h_1(x) + min_y h_2(y) = 0$ when x =0 and y =0\n",
    "\n",
    "$$min ~f(x,y) =0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "f = lambda x , y : 80* (x**4) + 0.01 * (y**6)\n",
    "def grad_f(x, y):\n",
    "    dx = 320 * x**3\n",
    "    dy = 0.06 * y**5\n",
    "    return dx , dy \n",
    "# we know that the function is Convex define there for to find the \n",
    "# minimun we will keep iterating until we over pass the minimun\n",
    "def gradiant_decent(x,y, lr, max_iter=1_000):\n",
    "    fx = f(x,y)\n",
    "    for _ in range(max_iter):\n",
    "        dx , dy = grad_f(x,y)\n",
    "        x , y = [x-(lr *dx), y-(lr *dy)]\n",
    "        fx_t = f(x,y)\n",
    "        if abs(fx_t-fx) < 1e-4:\n",
    "            break\n",
    "    return fx_t, x , y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0074345637125158345, 0.03939547429021935, 0.9476364408286969)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1.2\n",
    "gradiant_decent(1,1,0.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0015968975288613062, 0.012494699585181276, 0.7364180223311386)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1.3\n",
    "gradiant_decent(1,1,0.001, 10_000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assume that the see that that surface comes from an ill matrix, meaning is easy to convarge on x but not on y \n",
    "\n",
    "### part 2\n",
    "\n",
    "we will plot the surface and the line of the gradiand in 100 points each after 10 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = []\n",
    "x =[]\n",
    "y = []\n",
    "g =gradiant_decent(1,1,0.001, 100)\n",
    "for steps in range(1000):\n",
    "    res = gradiant_decent(1,1,0.001, steps * 10 +1)\n",
    "    fx.append(res[0])\n",
    "    x.append(res[1])\n",
    "    y.append(res[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alejandro\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\matplotlib\\figure.py:2022: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "# Make data.\n",
    "X = np.arange(-1.2, 1.2, 0.02)\n",
    "Y = np.arange(-1.2, 1.2, 0.02)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = f(X,Y)\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z,\n",
    "                       linewidth=0, antialiased=False)\n",
    "ax.plot(x,y,fx)\n",
    "ax.view_init(20,120)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the hessian is a diagonal matrix given that there is no dependecy between x , y \n",
    "there for $H = matrix{960 x^2&0\\\\0$0.03y^4}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nabla(x,y):\n",
    "    grad = np.array(grad_f(x,y)).reshape([2,1])\n",
    "    hess = np.array([960*x**2, 0, 0, 0.03*y**4]).reshape([2,2])\n",
    "    return -1 * np.linalg.inv(hess) @ grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiant_decent_N(x,y,lr =1e-4, max_iter=1_000):\n",
    "    fx = f(x,y)\n",
    "    x = np.array([x,y]).reshape([2,1])\n",
    "    m=0 \n",
    "    for _ in range(max_iter):\n",
    "        \n",
    "        wx = nabla(x[0][0],x[1][0])\n",
    "        x += wx\n",
    "        fx_t = f(x[0][0],x[1][0])\n",
    "        if abs(fx_t-fx) < 1e-4:\n",
    "            break\n",
    "    return  x , y, _,fx_t,abs(fx_t-fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1.01176233e-108],\n        [  1.00000000e+000]]), 1.0, 999, 0.01, 80.0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradiant_decent_N(1.0,1.0,10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
